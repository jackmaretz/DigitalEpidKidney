{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytrends.request import TrendReq\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats.stats import pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "df_gt = pd.read_csv('data/BRFSS/2012_AA.csv', sep=\";\",usecols=[\"LocationDesc\"])\n",
    "df_gt.dropna(subset=['LocationDesc'], inplace=True)\n",
    "df_gt.drop(df_gt.tail(2).index, inplace=True)\n",
    "states = df_gt[\"LocationDesc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_google_trends_df(kword, states, years=[2011,2012,2013,2014,2015,2016], output=True):\n",
    "    if output:\n",
    "        print(\"calculating indexes for\", kword)\n",
    "    yearly_google_trends_df = pd.DataFrame(index=states, columns=years, dtype=np.float)\n",
    "    for year in years:\n",
    "        values = []\n",
    "        try:\n",
    "            pytrends.build_payload([kword], cat=0, timeframe=str(year)+'-01-01'+ ' ' + str(year) + '-12-31', geo='US', gprop='')\n",
    "            trends_per_region_df = pytrends.interest_by_region()\n",
    "            for state in states:\n",
    "                if state not in trends_per_region_df.index:\n",
    "                    values.append(0)\n",
    "                else: \n",
    "                    values.append(int(trends_per_region_df.loc[state].values))\n",
    "            yearly_google_trends_df[year] = values\n",
    "        except: \n",
    "            raise Exception('Not relevant keyword in GoogleTrends database')\n",
    "    return yearly_google_trends_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def overall_correlation_df(gt_filename, google_trends_keywords, years):\n",
    "    df_gt = pd.read_csv(gt_filename, sep=\";\",usecols=[\"LocationDesc\",\"Data_Value\"])\n",
    "    df_gt.dropna(subset=['LocationDesc'], inplace=True)\n",
    "    df_gt.drop(df_gt.tail(2).index, inplace=True)\n",
    "    states = df_gt[\"LocationDesc\"]\n",
    "    bad_keywords = []\n",
    "    year_average_corr = []\n",
    "    for kw in google_trends_keywords:\n",
    "        try:\n",
    "            df = build_google_trends_df(kw, states=states, years=years, output=True )\n",
    "            df[\"ground_truth_value\"] = df_gt[\"Data_Value\"].values\n",
    "            corr_per_year= []\n",
    "            for year in years:\n",
    "                corr = pearsonr(df[year], df[\"ground_truth_value\"])[0]\n",
    "                if np.isnan(corr):\n",
    "                    raise Exception('Pearson correlation resulted in NaN')\n",
    "                corr_per_year.append(corr) # pos0: corr; pos1: p_value\n",
    "            year_average_corr.append(np.mean(corr_per_year))\n",
    "        except:\n",
    "            bad_keywords.append(kw)\n",
    "    good_keywords = [kw for kw in google_trends_keywords if kw not in bad_keywords] # remove the bad keywords, ie. with no results in the period\n",
    "    corr_df = pd.DataFrame(index=good_keywords,data=year_average_corr, columns=[\"correlation\"])\n",
    "    return corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating indexes for liver disease\n",
      "calculating indexes for diabetes\n",
      "calculating indexes for renal failure\n",
      "calculating indexes for hypertension\n",
      "calculating indexes for disease\n",
      "calculating indexes for kidney\n",
      "calculating indexes for cardiovascular disease\n",
      "calculating indexes for cirrhosis\n",
      "calculating indexes for nephritis\n",
      "calculating indexes for cardiomyopathy\n",
      "calculating indexes for emphysema\n",
      "calculating indexes for cystic fibrosis\n",
      "calculating indexes for glaucoma\n",
      "calculating indexes for sickle cell anemia\n",
      "calculating indexes for diabetes mellitus\n",
      "calculating indexes for coronary artery disease\n",
      "calculating indexes for juvenile diabetes\n",
      "calculating indexes for congestive heart failure\n",
      "calculating indexes for genetic disorder\n",
      "calculating indexes for anemia\n",
      "calculating indexes for pancreatitis\n",
      "calculating indexes for atherosclerosis\n",
      "calculating indexes for hypothyroidism\n",
      "calculating indexes for diabetic\n",
      "calculating indexes for Kawasaki Disease\n",
      "calculating indexes for degenerative disorder\n",
      "calculating indexes for rheumatic fever\n",
      "calculating indexes for nephrotic syndrome\n",
      "calculating indexes for valvular heart disease\n",
      "calculating indexes for metabolic disorder\n",
      "calculating indexes for liver\n",
      "calculating indexes for arteriosclerosis\n",
      "calculating indexes for gout\n",
      "calculating indexes for autoimmune disease\n",
      "calculating indexes for retinopathy\n",
      "calculating indexes for osteoporosis\n",
      "calculating indexes for kidney failure\n",
      "calculating indexes for heart disease\n",
      "calculating indexes for chronic renal failure\n",
      "calculating indexes for liver cancer\n",
      "calculating indexes for polycystic kidney disease\n",
      "calculating indexes for colon cancer\n",
      "calculating indexes for cancer\n",
      "calculating indexes for lupus\n",
      "calculating indexes for dementia\n",
      "calculating indexes for leukemia\n",
      "calculating indexes for hemolytic anemia\n",
      "calculating indexes for lung cancer\n",
      "calculating indexes for iron overload\n",
      "calculating indexes for pancreatic cancer\n",
      "calculating indexes for acute myeloid leukemia\n",
      "calculating indexes for prostate cancer\n",
      "calculating indexes for epilepsy\n",
      "calculating indexes for macular degeneration\n",
      "calculating indexes for pneumonia\n",
      "calculating indexes for scleroderma\n",
      "calculating indexes for lymphoblastic leukemia\n",
      "calculating indexes for lymphoma\n",
      "calculating indexes for hemochromatosis\n",
      "calculating indexes for histiocytosis\n",
      "calculating indexes for rheumatic disease\n",
      "calculating indexes for multiple myeloma\n",
      "calculating indexes for nephrosis\n",
      "calculating indexes for celiac disease\n",
      "calculating indexes for amyloidosis\n",
      "calculating indexes for arthritis\n",
      "calculating indexes for aplastic anemia\n",
      "calculating indexes for degenerative\n",
      "calculating indexes for hypertrophic cardiomyopathy\n",
      "calculating indexes for renal insufficiency\n",
      "calculating indexes for aortic stenosis\n",
      "calculating indexes for asthma\n",
      "calculating indexes for multiple sclerosis\n",
      "calculating indexes for preeclampsia\n",
      "calculating indexes for rheumatoid arthritis\n",
      "calculating indexes for uremia\n",
      "calculating indexes for prediabetes\n",
      "calculating indexes for vasculitis\n",
      "calculating indexes for sleep apnea\n",
      "calculating indexes for chronic lymphocytic leukemia\n",
      "calculating indexes for lupus erythematosus\n",
      "calculating indexes for systemic lupus erythematosus\n",
      "calculating indexes for familial hypercholesterolemia\n",
      "calculating indexes for ketoacidosis\n",
      "calculating indexes for cataracts\n",
      "calculating indexes for myotonic muscular dystrophy\n",
      "calculating indexes for hyperparathyroidism\n",
      "calculating indexes for dialysis\n",
      "calculating indexes for sepsis\n",
      "calculating indexes for ulcerative colitis\n",
      "calculating indexes for pemphigus\n",
      "calculating indexes for hyperkalemia\n",
      "calculating indexes for inflammatory bowel disease\n",
      "calculating indexes for neurological disorder\n",
      "calculating indexes for antinephritic\n",
      "calculating indexes for lymphocytic leukemia\n",
      "calculating indexes for hyponatremia\n",
      "calculating indexes for illness\n",
      "calculating indexes for muscular dystrophy\n",
      "calculating indexes for lichen planus\n",
      "calculating indexes for leukodystrophy\n",
      "calculating indexes for hydrocephalus\n",
      "calculating indexes for breast cancer\n",
      "calculating indexes for nephric\n",
      "calculating indexes for glandular disease\n",
      "calculating indexes for renal\n",
      "calculating indexes for assident\n",
      "calculating indexes for sugar diabetes\n",
      "calculating indexes for deficiency disease\n",
      "calculating indexes for perinephritis\n",
      "calculating indexes for mucoviscidosis\n",
      "calculating indexes for pyelitis\n",
      "calculating indexes for necrobiosis lipoidica\n",
      "calculating indexes for uropathy\n",
      "calculating indexes for toxemia of pregnancy\n",
      "calculating indexes for cyanopathy\n",
      "calculating indexes for nephropathy\n",
      "calculating indexes for hypercalcinuria\n",
      "calculating indexes for diabetes insipidus\n",
      "calculating indexes for Christmas Disease\n",
      "calculating indexes for diagnosticate\n",
      "calculating indexes for nephroptosis\n",
      "calculating indexes for autosomal dominant disease\n",
      "calculating indexes for fatty liver\n",
      "calculating indexes for anuresis\n",
      "calculating indexes for emia\n",
      "calculating indexes for abnormal condition\n",
      "calculating indexes for fibrosis\n",
      "calculating indexes for conversion disorder\n",
      "calculating indexes for keratomalacia\n",
      "calculating indexes for aemia\n",
      "calculating indexes for rachischisis\n",
      "calculating indexes for nephrolith\n",
      "calculating indexes for renal corpuscle\n",
      "calculating indexes for renal cortex\n",
      "calculating indexes for tetralogy of fallot\n",
      "calculating indexes for chronic\n",
      "calculating indexes for interrenal\n",
      "calculating indexes for azotemic\n",
      "calculating indexes for coeliac disease\n",
      "calculating indexes for pulmonary emphysema\n",
      "calculating indexes for idiopathy\n",
      "calculating indexes for nervous disorder\n",
      "calculating indexes for gas gangrene\n",
      "calculating indexes for hyperthyroidism\n",
      "calculating indexes for kalemia\n",
      "calculating indexes for cardiovascular\n",
      "calculating indexes for hyperinosis\n",
      "calculating indexes for cat scratch disease\n",
      "calculating indexes for amyotrophic lateral sclerosis\n",
      "calculating indexes for coronary thrombosis\n",
      "calculating indexes for cor pulmonale\n",
      "calculating indexes for hepatocystic\n",
      "calculating indexes for splenization\n",
      "calculating indexes for high blood pressure\n",
      "calculating indexes for anuretic\n",
      "calculating indexes for rheumides\n",
      "calculating indexes for xenodiagnosis\n",
      "calculating indexes for gulf war syndrome\n",
      "calculating indexes for arterialization\n",
      "calculating indexes for gastrohepatic\n",
      "calculating indexes for dermatopathic\n",
      "calculating indexes for respiratory disease\n",
      "calculating indexes for Williams Syndrome\n",
      "calculating indexes for Newcastle Disease\n",
      "calculating indexes for cancroid\n",
      "calculating indexes for hepatogastric\n",
      "calculating indexes for diagnose\n",
      "calculating indexes for albuminuria\n",
      "calculating indexes for nephrite\n",
      "calculating indexes for Pkd\n",
      "calculating indexes for oliguria\n",
      "calculating indexes for gravel\n",
      "calculating indexes for gravelled\n",
      "calculating indexes for nephroangiosclerosis\n",
      "calculating indexes for nephrosclerosis\n",
      "calculating indexes for nephria\n",
      "calculating indexes for nephroid\n",
      "calculating indexes for polycystic\n",
      "calculating indexes for chlorothiazide\n",
      "calculating indexes for leptospirosis\n",
      "calculating indexes for stone\n",
      "calculating indexes for stoned\n",
      "calculating indexes for stoning\n",
      "calculating indexes for transplantation\n",
      "calculating indexes for urine\n",
      "calculating indexes for French\n",
      "calculating indexes for polydipsia\n",
      "calculating indexes for rheumatism\n",
      "calculating indexes for ray\n",
      "calculating indexes for azotemia\n",
      "calculating indexes for haematuria\n",
      "calculating indexes for anuria\n",
      "calculating indexes for ballottement\n",
      "calculating indexes for donor\n",
      "calculating indexes for erythropoietin\n",
      "calculating indexes for glomerulonephritis\n",
      "calculating indexes for hemodialysis\n",
      "calculating indexes for hemodialyzer\n",
      "calculating indexes for hydronephrosis\n",
      "calculating indexes for mannitol\n",
      "calculating indexes for nephrectomy\n",
      "calculating indexes for nephrology\n",
      "calculating indexes for organ\n",
      "calculating indexes for pyelonephritis\n",
      "calculating indexes for spironolactone\n",
      "calculating indexes for viscus\n",
      "calculating indexes for azathioprine\n",
      "calculating indexes for calyx\n",
      "calculating indexes for capsule\n"
     ]
    }
   ],
   "source": [
    "wls = pd.read_csv(\"data/kidney_disease_related_terms.csv\",sep=\".\", names=[\"related_terms\"])\n",
    "kw_list = wls[\"related_terms\"].str.strip()\n",
    "years = [2011,2012,2013,2014,2015,2016]\n",
    "\n",
    "folder = 'data/BRFSS/'\n",
    "#files_sufix = ['2011_AA','2012_AA','2013_AA','2014_AA','2015_AA','2016_AA','2011','2012','2013','2014','2015','2016']\n",
    "files_sufix = ['2011']\n",
    "overall_corr_dict = {}\n",
    "for sufix in files_sufix:\n",
    "    df = overall_correlation_df(gt_filename=folder+sufix+'.csv',\n",
    "                                google_trends_keywords=kw_list,\n",
    "                                years = years)\n",
    "    df.to_csv('data/correlation/overall_correlation_' + sufix + '.csv',sep=\";\", index=True, header=True, index_label='keyword')\n",
    "    overall_corr_dict[sufix] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from a datafram |keyword|correlation|, get a subset of this dataframe according to the threshold, which can be float or int.\n",
    "# If it is float, it will return the keywords with correlation greater or equal then threshold. If it, it will return the first\n",
    "# threshold-terms. If not a float, nor a int is passed, raise an AttributeError.\n",
    "def get_most_correlated_terms_df(df, threshold=0.1):\n",
    "    # order the keywords by the correlation average value\n",
    "    df.sort_values(by=\"correlation\", ascending=False, inplace=True)\n",
    "    if isinstance(threshold, float):\n",
    "        return df.loc[df[\"correlation\"] >= threshold]\n",
    "    elif isinstance(threshold, int):\n",
    "        return df.head(threshold)\n",
    "    raise AttributeError(\"Exception in get_most_correlated_terms method. 'threshold' must be float or int.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from a datafram |keyword|correlation|, get a subset of this dataframe according to the threshold, which can be float or int.\n",
    "# If it is float, it will return the keywords with correlation greater or equal then threshold. If it, it will return the first\n",
    "# threshold-terms. If not a float, nor a int is passed, raise an AttributeError.\n",
    "def get_compound_most_correlated_terms_df(location='data/correlation/', file_type=\"AA\", \n",
    "                                          years = [2011,2012,2013,2014,2015,2016], threshold=0.1):\n",
    "    most_correlated_df = pd.DataFrame(columns=[\"keyword\",\"correlation\"])\n",
    "    \n",
    "    sufix = \"\"\n",
    "    if file_type == 'AA':\n",
    "        sufix = \"_\" + file_type\n",
    "    for year in years:\n",
    "        df = pd.read_csv(location + 'overall_correlation_'+ str(year) + sufix + '.csv', sep=';')\n",
    "        df = get_most_correlated_terms_df(df, threshold=threshold)\n",
    "        most_correlated_df = most_correlated_df.append(get_most_correlated_terms_df(df, threshold=threshold))\n",
    "    df.sort_values(by=\"correlation\", ascending=False, inplace=True)\n",
    "    most_correlated_df.drop_duplicates(subset=\"keyword\", keep=\"first\", inplace=True)\n",
    "    return most_correlated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_trends_most_correlated_terms_df_old(gt_filename, threshold, years = [2011,2012,2013,2014,2015,2016]):\n",
    "    df = pd.read_csv(gt_filename, sep=';')\n",
    "    most_correlated_keywords = (get_most_correlated_terms_df(df, threshold))[\"keyword\"].values\n",
    "    \n",
    "    print(\"With the threshold applied it was found \" + str(len(most_correlated_keywords)) + \" keywords.\")\n",
    "    \n",
    "    output_df = pd.DataFrame(columns=[\"State\", \"Year\"] + list(most_correlated_keywords))\n",
    "    first_iteration = True\n",
    "    for keyword in most_correlated_keywords:\n",
    "        df = build_google_trends_df(keyword, states, years=[2011,2012,2013,2014,2015,2016], output=True)\n",
    "        series = df.stack()  # convert columns into rows, it returns a series with just one column\n",
    "        series.to_csv(path=\"data/temp/temp.csv\", sep=\"\\t\", header=True)\n",
    "        df = pd.read_csv(\"data/temp/temp.csv\", sep=\"\\t\")\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        df.columns = [\"State\", \"Year\", keyword]\n",
    "        df.sort_values(['Year','State'], inplace=True)\n",
    "\n",
    "        # in the first iteration it is necessary to populate the year and state columns\n",
    "        if first_iteration:\n",
    "            output_df = df\n",
    "            first_iteration = False\n",
    "        else:\n",
    "            output_df[keyword] = df[keyword]\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_trends_most_correlated_terms_df(file_type=\"AA\", threshold=0.1, years = [2011,2012,2013,2014,2015,2016]):\n",
    "    # get the most correlated terms through all the years compering with all the ground truth data availabe (for each type,\n",
    "    # for example, AA or CP)\n",
    "    most_correlated_keywords = (get_compound_most_correlated_terms_df(location='data/correlation/', \n",
    "                                                                      file_type=\"AA\",\n",
    "                                                                      years = [2011,2012,2013,2014,2015,2016], \n",
    "                                                                      threshold=0.1))[\"keyword\"].values\n",
    "    \n",
    "    print(\"With the threshold applied it was found \" + str(len(most_correlated_keywords)) + \" keywords.\")\n",
    "    \n",
    "    output_df = pd.DataFrame(columns=[\"State\", \"Year\"] + list(most_correlated_keywords))\n",
    "    first_iteration = True\n",
    "    for keyword in most_correlated_keywords:\n",
    "        df = build_google_trends_df(keyword, states, years=[2011,2012,2013,2014,2015,2016], output=True)\n",
    "        series = df.stack()  # convert columns into rows, it returns a series with just one column\n",
    "        series.to_csv(path=\"data/temp/temp.csv\", sep=\"\\t\", header=True)\n",
    "        df = pd.read_csv(\"data/temp/temp.csv\", sep=\"\\t\")\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        df.columns = [\"State\", \"Year\", keyword]\n",
    "        df.sort_values(['Year','State'], inplace=True)\n",
    "\n",
    "        # in the first iteration it is necessary to populate the year and state columns\n",
    "        if first_iteration:\n",
    "            output_df = df\n",
    "            first_iteration = False\n",
    "        else:\n",
    "            output_df[keyword] = df[keyword]\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for ex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_regression_df(folder = 'data/BRFSS/', threshold=0.1, years = [2011,2012,2013,2014,2015,2016]):\n",
    "    \n",
    "    gt_type = ['_AA','CP']  # age adjusted or crude prevalence\n",
    "    for type_ in gt_type:\n",
    "        df_gt_output = pd.DataFrame(columns=\"Data_Value\")\n",
    "        for year in years:\n",
    "            gt_filename = folder + str(year) + gt_type + '.csv'\n",
    "            df_gt = pd.read_csv(gt_filename, sep=\";\", usecols=[\"Data_Value\"])\n",
    "            df_gt.drop(df_gt.tail(2).index, inplace=True)  # remove the results for puerto rico e guam\n",
    "            df_gt_output = df_gt_output.append(df_gt)\n",
    "            \n",
    "    output = pd.read_csv('data/output/output_complete.csv', sep=';')\n",
    "    \n",
    "    \n",
    "        \n",
    "folder = 'data/BRFSS/'\n",
    "#files_sufix = ['2011_AA','2012_AA','2013_AA','2014_AA','2015_AA','2016_AA','2011','2012','2013','2014','2015','2016']\n",
    "files_sufix = ['2016_AA']\n",
    "overall_corr_dict = {}\n",
    "for sufix in files_sufix:\n",
    "    df = overall_correlation_df(gt_filename=folder+sufix+'.csv',\n",
    "                                google_trends_keywords=kw_list,\n",
    "                                years = years)\n",
    "    df.to_csv('data/correlation/overall_correlation_' + sufix + '.csv',sep=\";\", index=True, header=True, index_label='keyword')\n",
    "    overall_corr_dict[sufix] = df\n",
    "    \n",
    "df_gt = pd.read_csv(gt_filename, sep=\";\",usecols=[\"LocationDesc\",\"Data_Value\"])\n",
    "    df_gt.dropna(subset=['LocationDesc'], inplace=True)\n",
    "    df_gt.drop(df_gt.tail(2).index, inplace=True)\n",
    "    states = df_gt[\"LocationDesc\"]\n",
    "    bad_keywords = []\n",
    "    year_average_corr = []\n",
    "    for kw in google_trends_keywords:\n",
    "        try:\n",
    "            df = build_google_trends_df(kw, states=states, years=years, output=True )\n",
    "            df[\"ground_truth_value\"] = df_gt[\"Data_Value\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = get_google_trends_most_correlated_terms_df(file_type=\"AA\", threshold=0.1, years = [2011,2012,2013,2014,2015,2016])\n",
    "output.to_csv(\"data/output/output_complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,7))\n",
    "plt.plot(corr_df, label =\"Age Adjusted prevalence\")\n",
    "\n",
    "plt.legend(fontsize=\"small\")\n",
    "plt.xlabel(\"query term\")\n",
    "plt.ylabel(\"Cor value \")\n",
    "plt.title(\"Correlation\")\n",
    "plt.grid()\n",
    "#plt.xticks(queries)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>renal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geoName</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorado</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connecticut</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District of Columbia</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Georgia</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hawaii</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idaho</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indiana</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iowa</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kansas</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kentucky</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Louisiana</th>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maine</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maryland</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Massachusetts</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michigan</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnesota</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mississippi</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missouri</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montana</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebraska</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Hampshire</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Jersey</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Mexico</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Carolina</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Dakota</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oklahoma</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rhode Island</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Carolina</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Dakota</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tennessee</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vermont</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Virginia</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      renal\n",
       "geoName                    \n",
       "Alabama                  73\n",
       "Alaska                   54\n",
       "Arizona                  69\n",
       "Arkansas                 71\n",
       "California               47\n",
       "Colorado                 53\n",
       "Connecticut              65\n",
       "Delaware                 63\n",
       "District of Columbia     52\n",
       "Florida                  64\n",
       "Georgia                  57\n",
       "Hawaii                   59\n",
       "Idaho                    57\n",
       "Illinois                 57\n",
       "Indiana                  72\n",
       "Iowa                     68\n",
       "Kansas                   60\n",
       "Kentucky                 75\n",
       "Louisiana                79\n",
       "Maine                    53\n",
       "Maryland                 72\n",
       "Massachusetts            67\n",
       "Michigan                 71\n",
       "Minnesota                64\n",
       "Mississippi              77\n",
       "Missouri                 70\n",
       "Montana                  46\n",
       "Nebraska                 77\n",
       "Nevada                   54\n",
       "New Hampshire            63\n",
       "New Jersey               58\n",
       "New Mexico               82\n",
       "New York                 57\n",
       "North Carolina           67\n",
       "North Dakota             62\n",
       "Ohio                     73\n",
       "Oklahoma                 82\n",
       "Oregon                   58\n",
       "Pennsylvania             74\n",
       "Rhode Island             59\n",
       "South Carolina           71\n",
       "South Dakota             84\n",
       "Tennessee                98\n",
       "Texas                    59\n",
       "Utah                     52\n",
       "Vermont                  67\n",
       "Virginia                 56\n",
       "Washington               47\n",
       "West Virginia           100\n",
       "Wisconsin                68\n",
       "Wyoming                  62"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = 2011\n",
    "kword = \"renal\"\n",
    "pytrends.build_payload([kword], cat=0, timeframe=str(year)+'-01-01'+ ' ' + str(year) + '-12-31', geo='US', gprop='')\n",
    "trends_per_region_df = pytrends.interest_by_region()\n",
    "trends_per_region_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
